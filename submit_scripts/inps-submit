#!/bin/bash -l

#SBATCH
#SBATCH --job-name=python_code
#SBATCH --time=20:0:0
#SBATCH --partition=parallel
#SBATCH --nodes=1
# number of tasks (processes) per node
#SBATCH --ntasks-per-node=24
# number of cpus (threads) per task (process)
#SBATCH --cpus-per-task=1
#SBATCH --mail-type=end
#SBATCH --mail-user=spark159@jhu.edu

#### load and unload modules you may need
module load bowtie2
module load samtools
module load python
module load R
#module load python/3.4.2
module list

#python2 scratch/bamtobed.py work/condense_seq/sp1_hg19_chr1.bam -o work/condense_seq/sp1_hg19_chr1
#python3 iNPS/iNPS_V1.2.2.py -i work/condense_seq/sp1_hg19_chr1.bed -o ./output1 --s_p p

#python2 scratch/bamtobed.py work/condense_seq/sp9_hg19_chr1.bam -o work/condense_seq/sp9_hg19_chr1
#python3 iNPS/iNPS_V1.2.2.py -i work/condense_seq/sp9_hg19_chr1.bed -o ./output9 --s_p p

#python2 scratch/bamtobed.py work/condense_seq/sp10_hg19_chr1.bam -o work/condense_seq/sp10_hg19_chr1
python3 iNPS/iNPS_V1.2.2.py -i work/condense_seq/sp10_hg19_chr1.bed -o ./output10 --s_p p

echo "Finished with job $SLURM_JOBID"

#### mpiexec by default launches number of tasks requested
