#!/bin/bash -l

#SBATCH
#SBATCH --job-name=sam_extract
#SBATCH --time=10:0:0
#SBATCH --partition=parallel
#SBATCH --nodes=1
# number of tasks (processes) per node
#SBATCH --ntasks-per-node=24
# number of cpus (threads) per task (process)
#SBATCH --cpus-per-task=1
#SBATCH --mail-type=end
#SBATCH --mail-user=spark159@jhu.edu

#### load and unload modules you may need
# module unload openmpi/intel
# module load mvapich2/gcc/64/2.0b
# module list
module load samtools/1.9
module list

#### execute code and write output file to OUT-24log.
samtools index work/condense_seq/sp1_hg19.sorted.bam
samtools index work/condense_seq/sp9_hg19.sorted.bam
samtools index work/condense_seq/sp10_hg19.sorted.bam
samtools view -b work/condense_seq/sp1_hg19.sorted.bam chr1 > work/condense_seq/sp1_hg19_chr1.bam
samtools view -b work/condense_seq/sp9_hg19.sorted.bam chr1 > work/condense_seq/sp9_hg19_chr1.bam
samtools view -b work/condense_seq/sp10_hg19.sorted.bam chr1 > work/condense_seq/sp10_hg19_chr1.bam
samtools index work/condense_seq/sp1_hg19_chr1.bam
samtools index work/condense_seq/sp9_hg19_chr1.bam
samtools index work/condense_seq/sp10_hg19_chr1.bam

echo "Finished with job $SLURM_JOBID"

#### mpiexec by default launches number of tasks requested
