#!/bin/bash -l

#SBATCH
#SBATCH --job-name=bowtie
#SBATCH --time=72:0:0
#SBATCH --partition=shared
#SBATCH --nodes=1
# number of tasks (processes) per node
#SBATCH --ntasks-per-node=24
# number of cpus (threads) per task (process)
#SBATCH --mail-type=end
#SBATCH --mail-user=spark159@jhu.edu

#### load and unload modules you may need
module load bowtie2
module load samtools
#module list

bowtie2 -p 24 -1 data/sp_spd_tests_detail/Sp-Spd_test1_S1_L001_R1_001.fastq.gz,data/sp_spd_tests_detail/Sp-Spd_test1_S1_L002_R1_001.fastq.gz -2 data/sp_spd_tests_detail/Sp-Spd_test1_S1_L001_R2_001.fastq.gz,data/sp_spd_tests_detail/Sp-Spd_test1_S1_L002_R2_001.fastq.gz -x work/condense_seq/hg19 -S data/sp_spd_tests_detail/sp1.sam
samtools view -S -b data/sp_spd_tests_detail/sp1.sam > data/sp_spd_tests_detail/sp1.bam
rm sp1.sam


echo "Finished with job $SLURM_JOBID"
